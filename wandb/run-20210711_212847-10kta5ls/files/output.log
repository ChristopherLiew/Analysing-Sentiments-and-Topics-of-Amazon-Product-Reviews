
  0%|                                                                      | 0/2151 [00:00<?, ?it/s]
  0%|                                                                      | 0/2151 [00:00<?, ?it/s]Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer.py", line 1269, in train
    tr_loss += self.training_step(model, inputs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer.py", line 1762, in training_step
    loss = self.compute_loss(model, inputs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer.py", line 1794, in compute_loss
    outputs = model(**inputs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 1032, in forward
    outputs = self.albert(
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1071, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 731, in forward
    encoder_outputs = self.encoder(
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 477, in forward
    layer_group_output = self.albert_layer_groups[group_idx](
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 429, in forward
    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 399, in forward
    ffn_output = apply_chunking_to_forward(
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2001, in apply_chunking_to_forward
    return forward_fn(*input_tensors)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 411, in ff_chunk
    ffn_output = self.activation(ffn_output)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/activations.py", line 42, in gelu_new
    return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))

>>> >>>
KeyboardInterrupt
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 183, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 755, in communicate_network_status
    resp = self._communicate(req, timeout=timeout, local=True)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 545, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 550, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 201, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 743, in communicate_stop_status
    resp = self._communicate(req, timeout=timeout, local=True)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 545, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 550, in _communicate_async
    raise Exception("The wandb backend process has shutdown")

>>> >>> >>>

>>> >>> >>> wandb
>>>
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
>>> # 4) Test on CoLab
>>> import os
>>> import torch
>>> import numpy as np
>>> from typing import Callable, Dict
>>> from datasets import load_dataset, load_metric
>>> from transformers import (
...     AutoTokenizer,
...     AutoModelForSequenceClassification,
...     DataCollatorWithPadding,
...     Trainer,
...     TrainingArguments,
...     EvalPrediction,
... )
>>> from transformers.integrations import (
...     TensorBoardCallback,
...
... )
>>> from pathlib import Path
>>> import wandb
>>> wandb.login()
True
>>>
>>> os.environ['WANDB_LOG_MODEL'] = True
>>>
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/local/bin/../../../Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/os.py", line 680, in __setitem__
    value = self.encodevalue(value)
  File "/usr/local/bin/../../../Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/os.py", line 750, in encode
    raise TypeError("str expected, not %s" % type(value).__name__)
>>> os.environ['WANDB_LOG_MODEL'] = 'true'
>>> wandb.init(project='amz-sent-analysis',
...            entity='chrisliew')
<wandb.sdk.wandb_run.Run object at 0x7fb9daaf51f0>
>>> # Constants
>>> PRE_TRAINED_MODEL_NAME = 'albert-base-v2'
>>> ROOT = Path('data/processed_hf')
>>> MODEL_SAVE_DIR = Path('store/sent_clf_models')
>>>
>>> # Check system for GPU
>>> device = torch.device("cuda") if torch.cuda.is_available()\
...      else torch.device("cpu")
>>> print(f'Device type: {device}')
Device type: cpu
>>> Dataset filepaths
>>> data_files = dict()
>>> data_files['train'] = str(ROOT / 'train.csv')
>>> data_files['validation'] = str(ROOT / 'validation.csv')
>>> data_files['test'] = str(ROOT / 'test.csv')
>>>
>>>
  File "<stdin>", line 1
    Dataset filepaths
            ^
>>> Load raw dataset and train-test split
>>> datasets = load_dataset('csv', data_files=data_files)
  File "<stdin>", line 1
    Load raw dataset and train-test split
         ^
SyntaxError: invalid syntax
>>>
Using custom data configuration default-284fe23bcccc7fe7
>>> datasets
DatasetDict({
    train: Dataset({
        features: ['text', 'rating', 'label'],
        num_rows: 22931
    })
    validation: Dataset({
        features: ['text', 'rating', 'label'],
        num_rows: 2548
    })
    test: Dataset({
        features: ['text', 'rating', 'label'],
        num_rows: 2833
    })
})
>>> # Tokenizer and function
>>> tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)
Could not locate the tokenizer configuration file, will try to use the model config instead.
loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /Users/MacBookPro15/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88
Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_memory_blocks": 0,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "vocab_size": 30000
}
>>>
loading file https://huggingface.co/albert-base-v2/resolve/main/spiece.model from cache at /Users/MacBookPro15/.cache/huggingface/transformers/10be6ce6d3508f1fdce98a57a574283b47c055228c1235f8686f039287ff8174.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
loading file https://huggingface.co/albert-base-v2/resolve/main/tokenizer.json from cache at /Users/MacBookPro15/.cache/huggingface/transformers/828a43aa4b9d07e2b7d3be7c6bc10a3ae6e16e8d9c3a0c557783639de9eaeb1b.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
loading file https://huggingface.co/albert-base-v2/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/albert-base-v2/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/albert-base-v2/resolve/main/tokenizer_config.json from cache at None
>>> def tokenize_function(examples):
...     return tokenizer(examples['text'],
...                      padding='max_length',
...                      truncation=True)
...
>>>
>>> tokenized_datasets = datasets.map(
...     tokenize_function,
...     batched=True
... )
>>>
Loading cached processed dataset at /Users/MacBookPro15/.cache/huggingface/datasets/csv/default-284fe23bcccc7fe7/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-d6ba1977caf21213.arrow
Loading cached processed dataset at /Users/MacBookPro15/.cache/huggingface/datasets/csv/default-284fe23bcccc7fe7/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-69139a1307a1ac50.arrow
100%|█████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.57ba/s]
>>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
>>> model = AutoModelForSequenceClassification.from_pretrained(
...     PRE_TRAINED_MODEL_NAME,
...     num_labels=3
loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /Users/MacBookPro15/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88
Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_memory_blocks": 0,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "vocab_size": 30000
}
>>>
loading weights file https://huggingface.co/albert-base-v2/resolve/main/pytorch_model.bin from cache at /Users/MacBookPro15/.cache/huggingface/transformers/bf1986d976e9a8320cbd3a0597e610bf299d639ce31b7ca581cbf54be3aaa6d3.d6d54047dfe6ae844e3bf6e7a7d0aff71cb598d3df019361e076ba7639b1da9b
Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']
- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']
>>> # Metrics
>>> acc_metric = load_metric('accuracy')
>>> f1_metric = load_metric('f1')
>>> prec_metric = load_metric('precision')
>>> rec_metric = load_metric("recall")
>>>
>>>
>>> def compute_metrics(eval_pred: EvalPrediction
...                     ) -> Callable[[EvalPrediction], Dict]:
...     # Use glue
...     logits, labels = eval_pred
...     predictions = np.argmax(logits, axis=-1)
...     metrics = {
...         'accuracy': acc_metric.compute(predictions=predictions,
...                                        references=labels),
...         'f1': f1_metric.compute(predictions=predictions,
...                                 references=labels),
...         'precision': prec_metric.compute(predictions=predictions,
...                                          references=labels),
...         'recall': rec_metric.compute(predictions=predictions,
...                                      references=labels)
...         }
...     return metrics
...
...     overwrite_output_dir=True,
>>> training_args = TrainingArguments(
...     report_to='wandb',
...     output_dir=MODEL_SAVE_DIR,
...     overwrite_output_dir=True,
...     evaluation_strategy='epoch',
...     per_device_train_batch_size=32,
...     per_device_eval_batch_size=32,
...     learning_rate=5e-5,
...     weight_decay=0.01,
...     logging_steps=100,
...     run_name='training_on_amz_pdt_reviews'
... )
>>>
>>>
PyTorch: setting up devices
>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=tokenized_datasets['train'],
...     eval_dataset=tokenized_datasets['validation'],
...     data_collator=data_collator,
...     compute_metrics=compute_metrics
... )
>>>
>>>
  0%|                                                                      | 0/2151 [21:24<?, ?it/s]
>>>
The following columns in the training set  don't have a corresponding argument in `AlbertForSequenceClassification.forward` and have been ignored: rating, text.
***** Running training *****
  Num examples = 22931
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 2151
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer.py", line 1213, in train
    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer_callback.py", line 340, in on_train_begin
    return self.call_event("on_train_begin", args, state, control)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer_callback.py", line 378, in call_event
    result = getattr(callback, event)(
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/integrations.py", line 452, in on_train_begin
    self.setup(args, state, model, **kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/integrations.py", line 431, in setup
    self._wandb.config.update(combined_dict, allow_val_change=True)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_config.py", line 171, in update
        num_rows: 22931
        features: ['text', 'rating', 'labels'],
    train: Dataset({text', 'rating', 'labels'],
>>> train: Dataset({text', 'rating', 'labels'],
>>> tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)
>>> tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)
    self._backend.interface.publish_config(key=key, val=val, data=data)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 623, in publish_config
    self._publish_config(cfg)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 627, in _publish_config
    self._publish(rec)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 536, in _publish
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Could not locate the tokenizer configuration file, will try to use the model config instead.
loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /Users/MacBookPro15/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88
Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_memory_blocks": 0,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "vocab_size": 30000
}
>>> tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)
loading file https://huggingface.co/albert-base-v2/resolve/main/spiece.model from cache at /Users/MacBookPro15/.cache/huggingface/transformers/10be6ce6d3508f1fdce98a57a574283b47c055228c1235f8686f039287ff8174.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
loading file https://huggingface.co/albert-base-v2/resolve/main/tokenizer.json from cache at /Users/MacBookPro15/.cache/huggingface/transformers/828a43aa4b9d07e2b7d3be7c6bc10a3ae6e16e8d9c3a0c557783639de9eaeb1b.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
loading file https://huggingface.co/albert-base-v2/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/albert-base-v2/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/albert-base-v2/resolve/main/tokenizer_config.json from cache at None
>>> tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)


100%|███████████████████████████████████████████████████████████████| 23/23 [00:06<00:00,  3.77ba/s]
100%|█████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.37ba/s]
 33%|█████████████████████▋                                           | 1/3 [00:00<00:00,  3.48ba/s]

>>> model = AutoModelForSequenceClassification.from_pretrained(_NAME)
>>> model = AutoModelForSequenceClassification.from_pretrained(_NAME)
loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /Users/MacBookPro15/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88
Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_memory_blocks": 0,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "vocab_size": 30000
}
loading weights file https://huggingface.co/albert-base-v2/resolve/main/pytorch_model.bin from cache at /Users/MacBookPro15/.cache/huggingface/transformers/bf1986d976e9a8320cbd3a0597e610bf299d639ce31b7ca581cbf54be3aaa6d3.d6d54047dfe6ae844e3bf6e7a7d0aff71cb598d3df019361e076ba7639b1da9b
Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']
- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
>>> model = AutoModelForSequenceClassification.from_pretrained(_NAME)
>>> model = AutoModelForSequenceClassification.from_pretrained(_NAME)
>>> rec_metric = load_metric("recall")fication.from_pretrained(_NAME)
>>> rec_metric = load_metric("recall")fication.from_pretrained(_NAME)
...         }te_metrics(eval_pred: EvalPredictionom_pretrained(_NAME)
...         }te_metrics(eval_pred: EvalPredictionom_pretrained(_NAME)
...         }te_metrics(eval_pred: EvalPredictionom_pretrained(_NAME)
>>> training_args = TrainingArguments(lPredictionom_pretrained(_NAME)
>>> trainer = Trainer(ainingArguments(lPredictionom_pretrained(_NAME)
>>> trainer = Trainer(ainingArguments(lPredictionom_pretrained(_NAME)
>>> trainer = Trainer(ainingArguments(lPredictionom_pretrained(_NAME)
The following columns in the training set  don't have a corresponding argument in `AlbertForSequenceClassification.forward` and have been ignored: rating, text.
***** Running training *****
  Num examples = 22931
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 2151
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer.py", line 1213, in train
    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer_callback.py", line 340, in on_train_begin
    return self.call_event("on_train_begin", args, state, control)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer_callback.py", line 378, in call_event
    result = getattr(callback, event)(
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/integrations.py", line 452, in on_train_begin
    self.setup(args, state, model, **kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/integrations.py", line 431, in setup
    self._wandb.config.update(combined_dict, allow_val_change=True)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_config.py", line 171, in update
    self._callback(data=sanitized)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 875, in _config_callback
    self._backend.interface.publish_config(key=key, val=val, data=data)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 623, in publish_config
    self._publish_config(cfg)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 627, in _publish_config
    self._publish(rec)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 536, in _publish
    raise Exception("The wandb backend process has shutdown")
Truetrainer = Trainer(ainingArguments(lPredictionom_pretrained(_NAME)
Truetrainer = Trainer(ainingArguments(lPredictionom_pretrained(_NAME)
>>> wandb.init(project='amz-sent-analysis', ctionom_pretrained(_NAME)
>>> training_args = TrainingArguments(sis', ctionom_pretrained(_NAME)
>>> training_args = TrainingArguments(sis', ctionom_pretrained(_NAME)
>>> tb_cb = TensorBoardCallback()ents(sis', ctionom_pretrained(_NAME)
>>> tb_cb = TensorBoardCallback()ents(sis', ctionom_pretrained(_NAME)
  File "<stdin>", line 1
    Callbacks
    ^
IndentationError: unexpected indent
>>> tb_cb = TensorBoardCallback()ents(sis', ctionom_pretrained(_NAME)
The following columns in the training set  don't have a corresponding argument in `AlbertForSequenceClassification.forward` and have been ignored: rating, text.
***** Running training *****
  Num examples = 22931
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 2151
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer.py", line 1213, in train
    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer_callback.py", line 340, in on_train_begin
    return self.call_event("on_train_begin", args, state, control)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/trainer_callback.py", line 378, in call_event
    result = getattr(callback, event)(
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/integrations.py", line 452, in on_train_begin
    self.setup(args, state, model, **kwargs)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/transformers/integrations.py", line 431, in setup
    self._wandb.config.update(combined_dict, allow_val_change=True)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_config.py", line 171, in update
    self._callback(data=sanitized)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 875, in _config_callback
    self._backend.interface.publish_config(key=key, val=val, data=data)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 623, in publish_config
    self._publish_config(cfg)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 627, in _publish_config
    self._publish(rec)
  File "/Users/MacBookPro15/Desktop/GitHub/Analysing-sentiments-and-topics-of-amazon-reviews/.venv/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 536, in _publish
    raise Exception("The wandb backend process has shutdown")
